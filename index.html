<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Vision Theremin</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            touch-action: manipulation;
        }
        .video-container {
            position: relative;
            width: 100%;
            max-width: 960px;
            aspect-ratio: 16 / 9;
            margin: auto;
            border-radius: 0.75rem;
            overflow: hidden;
            box-shadow: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
        }
        #webcam, #overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 0.75rem;
        }
        #webcam {
            object-fit: cover;
        }
        #hud {
            position: absolute;
            bottom: 1rem;
            left: 1rem;
            display: flex;
            gap: 0.5rem;
            background-color: rgba(0,0,0,0.5);
            padding: 0.5rem;
            border-radius: 0.5rem;
            color: white;
            font-size: 0.875rem;
        }
        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            display: inline-block;
        }
        .ok { background-color: #4ade80; }
        .warn { background-color: #facc15; }
        .err { background-color: #f87171; }
    </style>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body class="bg-gray-900 text-gray-200 flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-5xl mx-auto">
        <h1 class="text-3xl md:text-4xl font-bold text-center mb-2 text-white">AI Vision Theremin</h1>
        <p id="envHint" class="text-center text-yellow-400 mb-4">Please use HTTPS or localhost to access the camera.</p>

        <div class="video-container bg-gray-800">
            <video id="webcam" autoplay playsinline></video>
            <canvas id="overlay"></canvas>
            <div id="hud"></div>
        </div>

        <div class="controls mt-6 p-4 bg-gray-800 rounded-xl shadow-lg">
            <div class="grid grid-cols-1 sm:grid-cols-2 md:grid-cols-3 gap-4">
                <!-- Main Controls -->
                <div class="flex items-center space-x-3">
                    <button id="startBtn" class="w-full bg-blue-600 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded-lg transition-colors disabled:bg-gray-500">Start</button>
                    <button id="stopBtn" class="w-full bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-4 rounded-lg transition-colors disabled:bg-gray-500" disabled>Stop</button>
                    <button id="muteBtn" class="bg-yellow-500 hover:bg-yellow-600 text-white font-bold p-2 rounded-lg transition-colors">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" clip-rule="evenodd" /><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M17 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2" /></svg>
                    </button>
                    <div class="flex items-center space-x-2">
                        <span id="camStatus" class="status-dot warn" title="Camera Status"></span>
                    </div>
                </div>

                <!-- Volume -->
                <div class="flex items-center col-span-1 md:col-span-2">
                    <label for="volume" class="text-sm font-medium mr-3">Volume</label>
                    <input id="volume" type="range" min="0" max="1" step="0.01" value="0.85" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
                </div>
                
                <!-- Instruments -->
                <div class="flex items-center">
                    <label for="leftInstrument" class="text-sm font-medium mr-3">Left Hand</label>
                    <select id="leftInstrument" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2"></select>
                </div>
                <div class="flex items-center">
                    <label for="rightInstrument" class="text-sm font-medium mr-3">Right Hand</label>
                    <select id="rightInstrument" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2"></select>
                </div>
                
                <!-- Scale -->
                <div class="flex items-center space-x-2">
                    <label for="scaleRoot" class="text-sm font-medium">Scale</label>
                    <select id="scaleRoot" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2">
                        <option>C4</option><option>C#4</option><option>D4</option><option>D#4</option><option>E4</option><option>F4</option><option>F#4</option><option>G4</option><option>G#4</option><option>A4</option><option>A#4</option><option>B4</option>
                    </select>
                    <select id="scaleType" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2">
                        <option value="major">Major</option><option value="minor">Minor</option><option value="pentatonic">Pentatonic</option><option value="blues">Blues</option>
                    </select>
                </div>

                <!-- Settings -->
                 <div class="flex items-center">
                    <label for="perfMode" class="text-sm font-medium mr-3">Performance</label>
                    <select id="perfMode" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2">
                        <option value="speed">Speed</option><option value="balanced" selected>Balanced</option><option value="quality">Quality</option>
                    </select>
                </div>
                 <div class="flex items-center">
                    <label for="mirror" class="text-sm font-medium mr-3">Mirror</label>
                    <select id="mirror" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2">
                        <option value="1">On</option><option value="0">Off</option>
                    </select>
                </div>
                 <div class="flex items-center">
                    <label for="draw" class="text-sm font-medium mr-3">Draw</label>
                    <select id="draw" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2">
                        <option value="1">On</option><option value="0">Off</option>
                    </select>
                </div>
            </div>
        </div>
    </div>

    <script type="module">
        import {
            FilesetResolver,
            HandLandmarker,
            FaceLandmarker,
            DrawingUtils
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest";

        // Official model URLs (Google Storage)
        const HAND_MODEL_URL = "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task";
        const FACE_MODEL_URL = "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task";

        /* ========= Environment Check ========= */
        const envHint = document.getElementById('envHint');
        if (location.protocol.startsWith('https') || location.hostname === 'localhost') {
            envHint.style.display = 'none';
        }

        /* ============== UI Elements ============== */
        const controlsGrid = document.querySelector('.controls .grid');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const muteBtn = document.getElementById('muteBtn');
        const camStatus = document.getElementById('camStatus');
        const webcamEl = document.getElementById('webcam');
        const canvasEl = document.getElementById('overlay');
        const ctx = canvasEl.getContext('2d');
        const hudEl = document.getElementById('hud');

        const leftInstrumentEl = document.getElementById('leftInstrument');
        const rightInstrumentEl = document.getElementById('rightInstrument');
        const scaleRootEl = document.getElementById('scaleRoot');
        const scaleTypeEl = document.getElementById('scaleType');
        const volumeEl = document.getElementById('volume');
        const perfModeEl = document.getElementById('perfMode');
        const mirrorEl = document.getElementById('mirror');
        const drawEl = document.getElementById('draw');

        /* ====== Sound Banks (dynamically injected) ====== */
        const SOUND_SETS = {
            electronic: ["Synth", "Piano", "Guitar", "Violin", "Brass", "Organ"],
            regional: ["Accordion", "Tuba", "Trumpet", "Vihuela", "Bajo Sexto"]
        };
        let soundSet = localStorage.getItem('soundSet') || 'electronic';

        // Create and inject the sound bank selector
        const soundRow = document.createElement('div');
        soundRow.className = 'flex items-center md:col-span-3';
        soundRow.innerHTML = `
          <label for="soundSetSel" class="text-sm font-medium mr-3">Sound Bank</label>
          <select id="soundSetSel" class="w-full bg-gray-700 border border-gray-600 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 p-2">
            <option value="electronic">Electronic</option>
            <option value="regional">Regional</option>
          </select>
        `;
        controlsGrid.appendChild(soundRow);
        const soundSetSel = soundRow.querySelector('#soundSetSel');
        soundSetSel.value = soundSet;

        /* ============ Global State ============ */
        let vision, handLandmarker, faceLandmarker;
        let isRunning = false;
        let maxHands = 2;
        let mirrorView = true;
        let drawLandmarks = true;
        let stream = null;

        /* ============== Audio Engine ============== */
        const AudioEngine = (() => {
            const AC = window.AudioContext || window.webkitAudioContext;
            const audioCtx = new AC({ latencyHint: 'interactive' });
            const masterGain = audioCtx.createGain();
            masterGain.gain.value = 0.85;
            const limiter = audioCtx.createDynamicsCompressor();
            limiter.threshold.value = -8;
            limiter.knee.value = 14;
            limiter.ratio.value = 12;
            limiter.attack.value = 0.002;
            limiter.release.value = 0.09;
            limiter.connect(masterGain);
            masterGain.connect(audioCtx.destination);

            // --- Musical Utilities ---
            const noteFreq = (note) => {
                const A4 = 440;
                const map = { C:0, 'C#':1, Db:1, D:2, 'D#':3, Eb:3, E:4, F:5, 'F#':6, Gb:6, G:7, 'G#':8, Ab:8, A:9, 'A#':10, Bb:10, B:11 };
                const match = note.match(/^([A-G]#?|Bb|Db|Gb)(\d)$/);
                const n = map[match[1]];
                const o = parseInt(match[2], 10);
                return A4 * Math.pow(2, (n - 9 + (o - 4) * 12) / 12);
            };
            
            const buildScale = (root = "C4", type = "major") => {
                const intervals = {
                    major: [0, 2, 4, 5, 7, 9, 11, 12],
                    minor: [0, 2, 3, 5, 7, 8, 10, 12],
                    pentatonic: [0, 2, 4, 7, 9, 12],
                    blues: [0, 3, 5, 6, 7, 10, 12]
                }[type] || [0, 2, 4, 5, 7, 9, 11, 12];
                const baseTable = { 'C':0, 'C#':1, 'D':2, 'D#':3, 'E':4, 'F':5, 'F#':6, 'G':7, 'G#':8, 'A':9, 'A#':10, 'B':11, 'Bb':10, 'Db':1, 'Gb':6, 'Ab':8, 'Eb':3 };
                const match = root.match(/^([A-G]#?|Bb|Db|Gb)(\d)$/);
                const base = baseTable[match[1]];
                const octave = parseInt(match[2], 10);
                const names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
                return intervals.map(semi => {
                    const total = base + semi + octave * 12;
                    return `${names[(total % 12 + 12) % 12]}${Math.floor(total / 12)}`;
                });
            };

            const makeLFO = (freq = 5, destParam, depth = 10, type = 'sine') => {
                const lfo = audioCtx.createOscillator();
                lfo.type = type;
                lfo.frequency.value = freq;
                const g = audioCtx.createGain();
                g.gain.value = depth;
                lfo.connect(g);
                g.connect(destParam);
                lfo.start();
                return { lfo, g };
            };
            
            // --- Instrument Presets (Refactored) ---
            const instrumentPresets = {
                "Synth": o => { o.osc.type='sawtooth'; o.osc2.type='square'; o.filter.frequency.value=12000; },
                "Piano": o => { o.osc.type='triangle'; o.osc2.type='square'; o.filter.frequency.value=6000; },
                "Guitar": o => { o.osc.type='sawtooth'; o.osc2.type='sawtooth'; o.filter.frequency.value=4200; },
                "Violin": o => { o.osc.type='sawtooth'; o.osc2.type='sawtooth'; o.filter.frequency.value=8000; },
                "Brass": o => { o.osc.type='square'; o.osc2.type='square'; o.filter.frequency.value=5000; },
                "Organ": o => { o.osc.type='square'; o.osc2.type='triangle'; o.filter.frequency.value=10000; },
                "Accordion": o => {
                    o.osc.type='sawtooth'; o.osc2.type='sawtooth';
                    o.detune = 8; o.osc.detune.value = -o.detune; o.osc2.detune.value = +o.detune;
                    o.filter.frequency.value = 3500; o.filter.Q.value=0.8;
                    o.lfo = makeLFO(5, o.gain.gain, 0.05, 'sine');
                },
                "Tuba": o => {
                    o.osc.type='sine'; o.osc2.type='square';
                    o.filter.frequency.value = 2200; o.filter.Q.value=0.7;
                    o.envShape = {a:0.012, d:0.12, s:0.75};
                },
                "Trumpet": o => {
                    o.osc.type='square'; o.osc2.type='sawtooth';
                    o.filter.frequency.value = 7500; o.filter.Q.value=0.9;
                    o.pitchEnv = true;
                },
                "Vihuela": o => {
                    o.osc.type='triangle'; o.osc2.type='triangle';
                    o.filter.frequency.value = 3800; o.filter.Q.value=0.9;
                    o.pluck = true;
                },
                "Bajo Sexto": o => { // Same as Vihuela for this simple model
                    o.osc.type='triangle'; o.osc2.type='triangle';
                    o.filter.frequency.value = 3800; o.filter.Q.value=0.9;
                    o.pluck = true;
                }
            };

            function applyPreset(name, voiceObject) {
                const presetFn = instrumentPresets[name];
                if (presetFn) presetFn(voiceObject);
            }

            // --- Voice Creation ---
            const createVoice = (instrument = "Synth", dest = limiter) => {
                const v = {};
                v.gain = audioCtx.createGain(); v.gain.gain.value = 0; v.gain.connect(dest);
                v.filter = audioCtx.createBiquadFilter(); v.filter.type = 'lowpass'; v.filter.frequency.value = 12000; v.filter.Q.value = 0.7; v.filter.connect(v.gain);
                v.osc = audioCtx.createOscillator(); v.osc2 = audioCtx.createOscillator(); v.osc.frequency.value = 220; v.osc2.frequency.value = 220; v.osc.start(); v.osc2.start();
                v.mix = audioCtx.createGain(); v.mix.gain.value = 0.72; v.osc.connect(v.mix); v.osc2.connect(v.mix); v.mix.connect(v.filter);

                const buf = audioCtx.createBuffer(1, audioCtx.sampleRate * 2, audioCtx.sampleRate);
                const data = buf.getChannelData(0);
                for (let i = 0; i < data.length; i++) data[i] = Math.random() * 2 - 1;
                const noise = audioCtx.createBufferSource(); noise.buffer = buf; noise.loop = true; noise.start();
                v.noiseGain = audioCtx.createGain(); v.noiseGain.gain.value = 0; noise.connect(v.noiseGain); v.noiseGain.connect(v.filter);

                applyPreset(instrument, v);

                v.setFreq = (f) => {
                    const now = audioCtx.currentTime;
                    if (v.pitchEnv) {
                        v.osc.frequency.cancelScheduledValues(now); v.osc2.frequency.cancelScheduledValues(now);
                        v.osc.frequency.setValueAtTime(f * 1.03, now); v.osc2.frequency.setValueAtTime(f * 1.03, now);
                        v.osc.frequency.exponentialRampToValueAtTime(Math.max(20, f), now + 0.05);
                        v.osc2.frequency.exponentialRampToValueAtTime(Math.max(20, f), now + 0.05);
                    } else {
                        v.osc.frequency.exponentialRampToValueAtTime(Math.max(20, f), now + 0.01);
                        v.osc2.frequency.exponentialRampToValueAtTime(Math.max(20, f * 0.999), now + 0.01);
                    }
                };
                v.env = (target = 0.65, a = 0.008, d = 0.06, s = 0.55) => {
                    if (v.envShape) { a = v.envShape.a; d = v.envShape.d; s = v.envShape.s; }
                    const now = audioCtx.currentTime;
                    v.gain.gain.cancelScheduledValues(now);
                    v.gain.gain.linearRampToValueAtTime(target, now + a);
                    v.gain.gain.linearRampToValueAtTime(target * s, now + a + d);
                };
                v.release = (r = 0.12) => {
                    const now = audioCtx.currentTime;
                    v.gain.gain.cancelScheduledValues(now);
                    v.gain.gain.setTargetAtTime(0, now, r);
                };
                v.strike = (tone = 440, velo = 1) => {
                    v.setFreq(tone);
                    const now = audioCtx.currentTime;
                    v.noiseGain.gain.cancelScheduledValues(now);
                    if (v.pluck) {
                        v.noiseGain.gain.setValueAtTime(0.11 * velo, now);
                        v.noiseGain.gain.exponentialRampToValueAtTime(0.001, now + 0.04);
                        v.env(Math.min(0.8, 0.5 + 0.4 * velo), 0.003, 0.05, 0.45);
                    } else {
                        v.noiseGain.gain.setValueAtTime(0.06 * velo, now);
                        v.noiseGain.gain.exponentialRampToValueAtTime(0.001, now + 0.06);
                        v.env(Math.min(0.8, 0.35 + 0.5 * velo), 0.004, 0.05, 0.6);
                    }
                };
                return v;
            };

            // --- Percussion ---
            const Drums = (() => {
                const createDrumSound = (setupFn) => (vel = 1) => {
                    const { osc, gain, filter, noise } = setupFn(vel);
                    if(osc) osc.connect(filter || gain);
                    if(noise) noise.connect(filter || gain);
                    if(filter) filter.connect(gain);
                    gain.connect(limiter);
                    if(osc) {
                        osc.start();
                        osc.stop(audioCtx.currentTime + 0.5);
                    }
                    if(noise) {
                        noise.start();
                        noise.stop(audioCtx.currentTime + 0.5);
                    }
                };

                const kick = createDrumSound(vel => {
                    const osc = audioCtx.createOscillator(); osc.type = 'sine';
                    const gain = audioCtx.createGain(); gain.gain.value = 0.0001;
                    const f0 = (soundSet === 'regional') ? 90 : 120;
                    const f1 = (soundSet === 'regional') ? 38 : 45;
                    osc.frequency.setValueAtTime(f0, audioCtx.currentTime);
                    osc.frequency.exponentialRampToValueAtTime(f1, audioCtx.currentTime + 0.18);
                    gain.gain.setValueAtTime(0.95 * vel, audioCtx.currentTime);
                    gain.gain.exponentialRampToValueAtTime(0.0001, audioCtx.currentTime + 0.22);
                    return { osc, gain };
                });

                const snare = createDrumSound(vel => {
                    const noise = audioCtx.createBufferSource();
                    const buf = audioCtx.createBuffer(1, audioCtx.sampleRate * 0.6, audioCtx.sampleRate);
                    const data = buf.getChannelData(0); for(let i=0; i<data.length; i++) data[i]=Math.random()*2-1;
                    noise.buffer = buf;
                    const filter = audioCtx.createBiquadFilter(); filter.type = 'bandpass';
                    filter.frequency.value = (soundSet === 'regional') ? 1800 : 2500;
                    filter.Q.value = (soundSet === 'regional') ? 0.7 : 0.5;
                    const gain = audioCtx.createGain(); gain.gain.value = (soundSet === 'regional') ? 1.0 * vel : 0.9 * vel;
                    const dur = (soundSet === 'regional') ? 0.22 : 0.18;
                    gain.gain.exponentialRampToValueAtTime(0.0001, audioCtx.currentTime + dur);
                    return { noise, filter, gain };
                });

                const hihat = (open = false, vel = 1) => {
                    const noise = audioCtx.createBufferSource();
                    const buf = audioCtx.createBuffer(1, audioCtx.sampleRate * 0.5, audioCtx.sampleRate);
                    const data = buf.getChannelData(0); for(let i=0; i<data.length; i++) data[i]=Math.random()*2-1;
                    noise.buffer = buf;
                    const filter = audioCtx.createBiquadFilter(); filter.type = 'highpass';
                    filter.frequency.value = (soundSet === 'regional') ? 8000 : 7000;
                    filter.Q.value = 0.8;
                    const gain = audioCtx.createGain(); gain.gain.value = (soundSet === 'regional') ? 0.7 * vel : 0.6 * vel;
                    const dur = open ? ((soundSet === 'regional') ? 0.42 : 0.35) : 0.08;
                    gain.gain.exponentialRampToValueAtTime(0.0001, audioCtx.currentTime + dur);
                    noise.connect(filter); filter.connect(gain); gain.connect(limiter);
                    noise.start(); noise.stop(audioCtx.currentTime + dur + 0.05);
                };

                const crash = createDrumSound(vel => {
                    const noise = audioCtx.createBufferSource();
                    const buf = audioCtx.createBuffer(1, audioCtx.sampleRate * 1.5, audioCtx.sampleRate);
                    const data = buf.getChannelData(0); for(let i=0; i<data.length; i++) data[i]=Math.random()*2-1;
                    noise.buffer = buf;
                    const filter = audioCtx.createBiquadFilter(); filter.type = 'bandpass'; filter.frequency.value = 5200; filter.Q.value = 0.35;
                    const gain = audioCtx.createGain(); gain.gain.value = 0.55 * vel;
                    gain.gain.exponentialRampToValueAtTime(0.0001, audioCtx.currentTime + 0.9);
                    return { noise, filter, gain };
                });

                return { kick, snare, hihat, crash };
            })();

            return {
                ctx: audioCtx,
                setVolume(v) { masterGain.gain.value = v; },
                buildScale, noteFreq, createVoice,
                drums: Drums
            };
        })();

        /* ======== Scale & Note Mapping ======== */
        let currentScale = AudioEngine.buildScale("C4", "major");
        const fingerToDegree = { thumb: 0, index: 1, middle: 2, ring: 3, pinky: 4 };
        const fingerMap = ["thumb", "index", "middle", "ring", "pinky"];

        function degreeToFreq(degree, bias = 0) {
            const idx = Math.min(currentScale.length - 1, Math.max(0, degree));
            const noteName = currentScale[idx];
            const baseFreq = AudioEngine.noteFreq(noteName);
            return baseFreq * Math.pow(2, bias / 12);
        }
        function updateScale() {
            currentScale = AudioEngine.buildScale(scaleRootEl.value, scaleTypeEl.value);
        }
        scaleRootEl.addEventListener('change', updateScale);
        scaleTypeEl.addEventListener('change', updateScale);
        volumeEl.addEventListener('input', e => AudioEngine.setVolume(parseFloat(e.target.value)));

        /* ======= Landmark Drawing ======= */
        const drawingUtils = new DrawingUtils(ctx);
        function drawHands(result) {
            ctx.save();
            result?.landmarks?.forEach((landmarks) => {
                drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS, { color: "#5dd6ff", lineWidth: 3 });
                drawingUtils.drawLandmarks(landmarks, { color: "#44d19f", radius: 4 });
            });
            ctx.restore();
        }
        function drawFace(result) {
            ctx.save();
            result?.faceLandmarks?.forEach(landmarks => {
                drawingUtils.drawLandmarks(landmarks, { color: "#ffc857", radius: 1.5 });
            });
            ctx.restore();
        }

        /* ============= Utilities ============= */
        const getHandednessKey = (handedness) => handedness.toLowerCase().startsWith("left") ? "L" : "R";
        
        function isFingerExtended(landmarks, finger, handKey) {
            const fingerIndices = { thumb: [1, 2, 3, 4], index: [5, 6, 7, 8], middle: [9, 10, 11, 12], ring: [13, 14, 15, 16], pinky: [17, 18, 19, 20] };
            const [mcp, pip, , tip] = fingerIndices[finger].map(i => landmarks[i]);
            if (finger === "thumb") {
                return (handKey === "R") ? (tip.x > mcp.x + 0.06) : (tip.x < mcp.x - 0.06);
            } else {
                return (pip.y - tip.y) > 0.035;
            }
        }
        
        const wristGain = (landmarks) => Math.min(1, Math.max(0, 1 - landmarks[0].y));
        const lerp = (a, b, t) => a + (b - a) * t;

        /* ======= Voice Management per Hand/Finger ======= */
        const activeVoices = {}; // e.g., "L_index" -> voice object
        function ensureVoice(key, instrument) {
            if (!activeVoices[key]) {
                activeVoices[key] = AudioEngine.createVoice(instrument);
            }
            return activeVoices[key];
        }
        function stopVoice(key) {
            if (activeVoices[key]) activeVoices[key].release();
        }

        /* =========== Face to Percussion Mapping =========== */
        const faceState = { blinkL: false, blinkR: false, mouth: false, tongue: false };
        const getBlendshapeMap = (blendshapes) => {
            const map = {};
            blendshapes?.categories?.forEach(c => map[c.categoryName] = c.score);
            return map;
        };
        const edgeTrigger = (prev, now, threshold = 0.55) => (!prev && now > threshold);

        function processFace(result) {
            if (!result || !result.faceBlendshapes || result.faceBlendshapes.length === 0) return;
            
            const blendshapes = getBlendshapeMap(result.faceBlendshapes[0]);
            const blinkL = blendshapes["eyeBlinkLeft"] ?? 0;
            const blinkR = blendshapes["eyeBlinkRight"] ?? 0;
            const mouthOpen = (blendshapes["mouthOpen"] ?? 0) + (blendshapes["jawOpen"] ?? 0) * 0.5;
            const tongueOut = blendshapes["tongueOut"] ?? 0;

            if (edgeTrigger(faceState.blinkL, blinkL)) AudioEngine.drums.hihat(false, 0.9);
            if (edgeTrigger(faceState.blinkR, blinkR)) AudioEngine.drums.hihat(true, 0.9);
            if (edgeTrigger(faceState.mouth, mouthOpen, 0.6)) AudioEngine.drums.snare(1.0);
            if (edgeTrigger(faceState.tongue, tongueOut, 0.55)) AudioEngine.drums.crash(1.0);

            if ((blinkL > 0.6 && blinkR > 0.6) && !(faceState.blinkL && faceState.blinkR)) {
                AudioEngine.drums.kick(1.0);
            }

            faceState.blinkL = blinkL > 0.55;
            faceState.blinkR = blinkR > 0.55;
            faceState.mouth = mouthOpen > 0.6;
            faceState.tongue = tongueOut > 0.55;

            hudEl.innerHTML = `
                <span class="pill">${faceState.blinkL ? '�️‍🗨️' : '👁️'} L</span>
                <span class="pill">${faceState.blinkR ? '👁️‍🗨️' : '👁️'} R</span>
                <span class="pill">${faceState.mouth ? '🗣️' : '🙂'}</span>
                <span class="pill">${faceState.tongue ? '👅' : '👄'}</span>
            `;
        }

        /* ========== Main Prediction Loop ========== */
        let lastInferenceTime = 0;
        const INFERENCE_SPEEDS = { speed: 1 / 45, balanced: 1 / 30, quality: 1 / 20 };

        async function predictionLoop() {
            if (!isRunning) return;
            
            const now = performance.now() / 1000;
            const minDelta = INFERENCE_SPEEDS[perfModeEl.value] || INFERENCE_SPEEDS.balanced;

            if (now - lastInferenceTime >= minDelta) {
                lastInferenceTime = now;
                const timestamp = performance.now();
                const handsResult = await handLandmarker.detectForVideo(webcamEl, timestamp);
                const faceResult = await faceLandmarker.detectForVideo(webcamEl, timestamp);

                ctx.clearRect(0, 0, canvasEl.width, canvasEl.height);
                if (drawLandmarks) {
                    drawHands(handsResult);
                    drawFace(faceResult);
                }

                processHands(handsResult);
                processFace(faceResult);
            }
            requestAnimationFrame(predictionLoop);
        }

        /* ====== Hand Music Engine ====== */
        const smoothYCoords = {};
        function processHands(result) {
            if (!result || !result.handedness) return;
            
            for (let i = 0; i < result.handedness.length; i++) {
                const handedness = result.handedness[i][0].categoryName;
                const handKey = getHandednessKey(handedness);
                const instrument = (handKey === "L") ? leftInstrumentEl.value : rightInstrumentEl.value;
                const landmarks = result.landmarks[i];
                const gain = wristGain(landmarks);

                for (const finger of fingerMap) {
                    const voiceKey = `${handKey}_${finger}`;
                    const degree = fingerToDegree[finger];
                    const tipIndex = { thumb: 4, index: 8, middle: 12, ring: 16, pinky: 20 }[finger];
                    const tip = landmarks[tipIndex];
                    
                    const smoothKey = `${voiceKey}_tip`;
                    const smoothedY = smoothYCoords[smoothKey] = lerp(smoothYCoords[smoothKey] ?? tip.y, tip.y, 0.35);
                    
                    const pitchBias = Math.round((0.5 - smoothedY) * 24); // ±12 semitones
                    const freq = degreeToFreq(degree, pitchBias);
                    const isExtended = isFingerExtended(landmarks, finger, handKey);

                    if (isExtended) {
                        const voice = ensureVoice(voiceKey, instrument);
                        voice.strike(freq, Math.max(0.2, gain));
                        voice.gain.gain.value = Math.min(0.9, (0.25 + 0.7 * gain));
                    } else {
                        stopVoice(voiceKey);
                    }
                }
            }
        }

        /* =========== Camera / Model Setup =========== */
        async function setupCamera() {
            stream = await navigator.mediaDevices.getUserMedia({
                video: { width: { ideal: 1280 }, height: { ideal: 720 }, frameRate: { ideal: 60, max: 60 } },
                audio: false
            });
            webcamEl.srcObject = stream;
            
            return new Promise((resolve) => {
                webcamEl.onloadedmetadata = () => {
                    webcamEl.play();
                    const vw = webcamEl.videoWidth;
                    const vh = webcamEl.videoHeight;
                    canvasEl.width = vw;
                    canvasEl.height = vh;
                    ctx.setTransform(1, 0, 0, 1, 0, 0);
                    if (mirrorEl.value === "1") {
                        ctx.translate(canvasEl.width, 0);
                        ctx.scale(-1, 1);
                    }
                    resolve();
                };
            });
        }
        
        async function loadModels() {
            const wasmBase = "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm";
            vision = await FilesetResolver.forVisionTasks(wasmBase);
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: HAND_MODEL_URL, delegate: "GPU" },
                numHands: maxHands,
                runningMode: "VIDEO"
            });
            faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: FACE_MODEL_URL, delegate: "GPU" },
                runningMode: "VIDEO",
                numFaces: 1,
                outputFaceBlendshapes: true,
                outputFacialTransformationMatrixes: false
            });
        }

        /* =========== UI Helpers =========== */
        function setInstrumentOptions(forSet) {
            const instruments = SOUND_SETS[forSet];
            const rebuild = (selectElement) => {
                const prevValue = selectElement.value;
                selectElement.innerHTML = instruments.map(x => `<option value="${x}">${x}</option>`).join('');
                if (instruments.includes(prevValue)) {
                    selectElement.value = prevValue;
                }
            };
            rebuild(leftInstrumentEl);
            rebuild(rightInstrumentEl);
        }
        setInstrumentOptions(soundSet);

        soundSetSel.addEventListener('change', () => {
            soundSet = soundSetSel.value;
            localStorage.setItem('soundSet', soundSet);
            setInstrumentOptions(soundSet);
        });

        mirrorEl.addEventListener('change', e => mirrorView = e.target.value === "1");
        drawEl.addEventListener('change', e => drawLandmarks = e.target.value === "1");

        /* =========== Main Controls =========== */
        startBtn.addEventListener('click', async () => {
            startBtn.disabled = true;
            startBtn.textContent = "Loading...";
            try {
                await AudioEngine.ctx.resume();
                AudioEngine.setVolume(parseFloat(volumeEl.value));
                await setupCamera();
                await loadModels();
                camStatus.className = "status-dot ok";
                isRunning = true;
                stopBtn.disabled = false;
                startBtn.textContent = "Start";
                predictionLoop();
            } catch (err) {
                console.error(err);
                camStatus.className = "status-dot err";
                envHint.textContent = `Error starting: ${err?.message || err}`;
                envHint.style.display = 'block';
                startBtn.disabled = false;
                startBtn.textContent = "Start";
            }
        });

        stopBtn.addEventListener('click', () => {
            isRunning = false;
            stopBtn.disabled = true;
            startBtn.disabled = false;
            camStatus.className = "status-dot warn";
            Object.keys(activeVoices).forEach(key => stopVoice(key));
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            ctx.setTransform(1, 0, 0, 1, 0, 0);
            ctx.clearRect(0, 0, canvasEl.width, canvasEl.height);
            hudEl.innerHTML = '';
        });

        muteBtn.addEventListener('click', () => {
            AudioEngine.setVolume(0);
            volumeEl.value = 0;
        });

        window.addEventListener('resize', () => {
            if (webcamEl.videoWidth) {
                canvasEl.width = webcamEl.videoWidth;
                canvasEl.height = webcamEl.videoHeight;
                ctx.setTransform(1, 0, 0, 1, 0, 0);
                if (mirrorEl.value === "1") {
                    ctx.translate(canvasEl.width, 0);
                    ctx.scale(-1, 1);
                }
            }
        });
    </script>
</body>
</html>
�
